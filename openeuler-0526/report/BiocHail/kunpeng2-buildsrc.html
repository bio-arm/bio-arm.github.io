<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<HTML>
<HEAD>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
<TITLE>Build/check report for BioC 3.18 - BUILD results for BiocHail on kunpeng2</TITLE>
<LINK rel="stylesheet" href="../report.css" type="text/css">
<SCRIPT type="text/javascript" src="../report.js"></SCRIPT>
</HEAD>
<BODY onLoad="initialize();">
<TABLE class="grid_layout" style="width: 100%; background: #EEE;"><TR><TD style="text-align: left; padding: 5px; vertical-align: middle;"><I>Back to <B>Build/check report for BioC 3.18</B>:&nbsp;&nbsp;&nbsp;<A href="../">simplified</A>&nbsp;&nbsp;&nbsp;<A href="../long-report.html">long</A></I></TD><TD><TABLE class="abc_dispatcher"><TR><TD><A href="..#A">A</A></TD><TD><B>[<A href="..#B">B</A>]</B></TD><TD><A href="..#C">C</A></TD><TD><A href="..#D">D</A></TD><TD><A href="..#E">E</A></TD><TD><A href="..#F">F</A></TD><TD><A href="..#G">G</A></TD><TD><A href="..#H">H</A></TD><TD><A href="..#I">I</A></TD><TD><A href="..#J">J</A></TD><TD><A href="..#K">K</A></TD><TD><A href="..#L">L</A></TD><TD><A href="..#M">M</A></TD><TD><A href="..#N">N</A></TD><TD><A href="..#O">O</A></TD><TD><A href="..#P">P</A></TD><TD><A href="..#Q">Q</A></TD><TD><A href="..#R">R</A></TD><TD><A href="..#S">S</A></TD><TD><A href="..#T">T</A></TD><TD><A href="..#U">U</A></TD><TD><A href="..#V">V</A></TD><TD><A href="..#W">W</A></TD><TD><A href="..#X">X</A></TD><TD><A href="..#Y">Y</A></TD><TD><A href="..#Z">Z</A></TD></TR></TABLE></TD></TR></TABLE>
<P class="time_stamp">
This page was generated on 2023-05-26 06:18:04 -0000 (Fri, 26 May 2023).
</P>
<TABLE class="node_specs">
<TR><TH>Hostname</TH><TH>OS</TH><TH>Arch&nbsp;(*)</TH><TH>R&nbsp;version</TH><TH style="text-align: right;">Installed&nbsp;pkgs</TH></TR>
<TR class="kunpeng2"><TD><B><A href="../kunpeng2-NodeInfo.html"><B>kunpeng2</B></A></B></TD><TD>Linux&nbsp;(openEuler&nbsp;22.03&nbsp;LTS-SP1)</TD><TD>aarch64</TD><TD>4.3.0&nbsp;(2023-04-21)&nbsp;--&nbsp;"Already&nbsp;Tomorrow"
</TD><TD style="text-align: right;"><A href="../kunpeng2-R-instpkgs.html">4254</A></TD></TR>
<TR><TD COLSPAN="5" style="font-size: smaller;"><I>Click on any hostname to see more info about the system (e.g. compilers) &nbsp;&nbsp;&nbsp;&nbsp; (*) as reported by 'uname -p', except on Windows and Mac OS X</I></TD></TR>
</TABLE>
<BR>
<H2><SPAN class="kunpeng2">BUILD results for BiocHail on kunpeng2</SPAN></H2>
<BR>
<DIV class="motd">
<TABLE><TR><TD>
To the developers/maintainers of the BiocHail package:<BR>
- Allow up to 24 hours (and sometimes 48 hours) for your latest push to git@git.bioconductor.org:packages/BiocHail.git to reflect on this report. See <A href="%s">Troubleshooting Build Report</A> for more information.<BR><BR>
- Use the following <A href="../Renviron.bioc">Renviron settings</A> to reproduce errors and warnings.<BR><BR>
Note: If "R CMD check" recently failed on the Linux builder over a missing dependency, add the missing dependency to "Suggests" in your DESCRIPTION file. See the <A href="../Renviron.bioc">Renviron.bioc</A> for details.
</TD></TR></TABLE>
</DIV>
<P style="text-align: center;"><A href="raw-results/">raw results</A><P>
<TABLE class="gcard_list">
<TBODY class="gcard error">
<TR class="header"><TD class="leftmost top_left_corner"></TD><TD>Package <B>174</B>/2197</TD><TD style="width: 75px;">Hostname</TD><TD style="width: 225px;">OS&nbsp;/&nbsp;Arch</TD><TD class="STAGE install">INSTALL</TD><TD class="STAGE buildsrc selected">BUILD</TD><TD class="STAGE checksrc">CHECK</TD><TD class="STAGE buildbin">BUILD BIN</TD><TD style="width: 12px;"></TD><TD class="rightmost top_right_corner"></TD></TR>
<TR class="selected_row"><TD ROWSPAN="2" class="leftmost bottom_left_corner"></TD><TD ROWSPAN="1" style="vertical-align: top;"><B><A href="./">BiocHail</A>&nbsp;1.1.1</B>&nbsp;&nbsp;<SPAN style="font-size: smaller; font-style: italic;">(<A href="/packages/3.18/BiocHail">landing page</A>)</SPAN><BR>Vincent Carey<BR><TABLE class="svn_info">
<TR><TD class="svn_info">Snapshot&nbsp;Date:&nbsp;<SPAN class="svn_info">2023-05-25&nbsp;13:29:39&nbsp;-0000&nbsp;(Thu,&nbsp;25&nbsp;May&nbsp;2023)</SPAN></TD></TR>
<TR><TD class="svn_info">git_url:&nbsp;<SPAN class="svn_info">https://git.bioconductor.org/packages/BiocHail</SPAN></TD></TR>
<TR><TD class="svn_info">git_branch:&nbsp;<SPAN class="svn_info">devel</SPAN></TD></TR>
<TR><TD class="svn_info">git_last_commit:&nbsp;<SPAN class="svn_info">8c3f2f4</SPAN></TD></TR>
<TR><TD class="svn_info">git_last_commit_date:&nbsp;<SPAN class="svn_info">2023-04-26&nbsp;13:09:00&nbsp;-0000&nbsp;(Wed,&nbsp;26&nbsp;Apr&nbsp;2023)</SPAN></TD></TR>
</TABLE>
</TD><TD class="kunpeng2 selected"><B>kunpeng2</B></TD><TD class="kunpeng2"><SPAN style="font-size: smaller;">Linux&nbsp;(openEuler&nbsp;22.03&nbsp;LTS-SP1)&nbsp;/&nbsp;aarch64</SPAN></TD><TD class="status kunpeng2 install"><A href="./kunpeng2-install.html" onmouseover="add_class_mouseover(this);" onmouseout="remove_class_mouseover(this);"><SPAN class="glyph OK">&nbsp;&nbsp;OK&nbsp;&nbsp;</SPAN></A></TD><TD class="status kunpeng2 buildsrc selected"><A href="./kunpeng2-buildsrc.html" onmouseover="add_class_mouseover(this);" onmouseout="remove_class_mouseover(this);"><SPAN class="glyph ERROR">&nbsp;&nbsp;ERROR&nbsp;&nbsp;</SPAN></A></TD><TD class="status kunpeng2 checksrc"><SPAN class="glyph skipped">skipped</SPAN></TD><TD class="status kunpeng2"></TD><TD class="status kunpeng2"></TD><TD ROWSPAN="2" class="rightmost bottom_right_corner"></TD></TR>
<TR class="footer"><TD COLSPAN="8"></TD></TR>
</TBODY>
</TABLE>
<HR>
<H3>Summary</H3>
<DIV class="kunpeng2 hscrollable">
<TABLE>
<TR><TD><B>Package</B>: BiocHail</TD></TR>
<TR><TD><B>Version</B>: 1.1.1</TD></TR>
<TR><TD><B>Command</B>: /home/biocbuild/R/R-4.3.0/bin/R CMD build --keep-empty-dirs --no-resave-data BiocHail</TD></TR>
<TR><TD><B>StartedAt</B>: 2023-05-25 20:37:54 -0000 (Thu, 25 May 2023)</TD></TR>
<TR><TD><B>EndedAt</B>: 2023-05-25 20:44:40 -0000 (Thu, 25 May 2023)</TD></TR>
<TR><TD><B>EllapsedTime</B>: 405.5 seconds</TD></TR>
<TR><TD><B>RetCode</B>: 1</TD></TR>
<TR><TD><B>Status</B>: <SPAN class="glyph ERROR">&nbsp;&nbsp;ERROR&nbsp;&nbsp;</SPAN></TD></TR>
<TR><TD><B>PackageFile</B>: None</TD></TR>
<TR><TD><B>PackageFileSize</B>: NA</TD></TR>
</TABLE>
</DIV>
<HR>
<H3>Command output</H3>
<DIV class="kunpeng2 hscrollable">
<PRE style="padding: 3px;">
##############################################################################
##############################################################################
###
### Running command:
###
###   /home/biocbuild/R/R-4.3.0/bin/R CMD build --keep-empty-dirs --no-resave-data BiocHail
###
##############################################################################
##############################################################################


* checking for file ‘BiocHail/DESCRIPTION’ ... OK
* preparing ‘BiocHail’:
* checking DESCRIPTION meta-information ... OK
* installing the package to build vignettes
* creating vignettes ... ERROR
--- re-building ‘gwas_tut.Rmd’ using rmarkdown
2023-05-25 20:38:20.193 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to &quot;WARN&quot;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
2023-05-25 20:38:21.415 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:21.418 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:21.421 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:21.425 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:21.429 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:21.433 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:21.437 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:21.441 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:21.445 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:21.448 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:21.452 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:21.494 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:21.498 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:21.502 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:21.506 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:21.512 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:21.520 ERROR SparkContext:94 - Error initializing SparkContext.
java.net.BindException: Cannot assign requested address: Service &#x27;sparkDriver&#x27; failed after 16 retries (on a random free port)! Consider explicitly setting the appropriate binding address for the service &#x27;sparkDriver&#x27; (for example spark.driver.bindAddress for SparkDriver) to the correct binding address.
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:555)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.netBind(ServerSocketChannelImpl.java:337)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:294)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:134)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:562)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1334)
	at io.netty.channel.AbstractChannelHandlerContext.invokeBind(AbstractChannelHandlerContext.java:506)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:491)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:973)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:260)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:356)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:833)
Initializing Hail with default parameters...
2023-05-25 20:38:22.049 WARN  SparkContext:69 - Another SparkContext is being constructed (or threw an exception in its constructor). This may indicate an error, since only one SparkContext should be running in this JVM (see SPARK-2243). The other SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:85)
is.hail.backend.spark.SparkBackend$.configureAndCreateSparkContext(SparkBackend.scala:148)
is.hail.backend.spark.SparkBackend$.apply(SparkBackend.scala:230)
is.hail.backend.spark.SparkBackend.apply(SparkBackend.scala)
java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.base/java.lang.reflect.Method.invoke(Method.java:568)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:282)
py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
py4j.commands.CallCommand.execute(CallCommand.java:79)
py4j.GatewayConnection.run(GatewayConnection.java:238)
java.base/java.lang.Thread.run(Thread.java:833)
2023-05-25 20:38:22.089 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.093 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.096 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.100 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.103 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.107 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.110 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.114 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.117 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.121 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.124 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.128 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.131 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.134 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.137 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.140 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.144 ERROR SparkContext:94 - Error initializing SparkContext.
java.net.BindException: Cannot assign requested address: Service &#x27;sparkDriver&#x27; failed after 16 retries (on a random free port)! Consider explicitly setting the appropriate binding address for the service &#x27;sparkDriver&#x27; (for example spark.driver.bindAddress for SparkDriver) to the correct binding address.
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:555)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.netBind(ServerSocketChannelImpl.java:337)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:294)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:134)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:562)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1334)
	at io.netty.channel.AbstractChannelHandlerContext.invokeBind(AbstractChannelHandlerContext.java:506)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:491)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:973)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:260)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:356)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:833)

Quitting from lines 75-79 [get1] (gwas_tut.Rmd)
Error: processing vignette &#x27;gwas_tut.Rmd&#x27; failed with diagnostics:
py4j.protocol.Py4JJavaError: An error occurred while calling z:is.hail.backend.spark.SparkBackend.apply.
&lt;... omitted ...&gt;a:491)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:973)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:260)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:356)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:833)

See `reticulate::py_last_error()` for details
--- failed re-building ‘gwas_tut.Rmd’

--- re-building ‘large_t2t.Rmd’ using rmarkdown
2023-05-25 20:38:22.238 WARN  SparkContext:69 - Another SparkContext is being constructed (or threw an exception in its constructor). This may indicate an error, since only one SparkContext should be running in this JVM (see SPARK-2243). The other SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:85)
is.hail.backend.spark.SparkBackend$.configureAndCreateSparkContext(SparkBackend.scala:148)
is.hail.backend.spark.SparkBackend$.apply(SparkBackend.scala:230)
is.hail.backend.spark.SparkBackend.apply(SparkBackend.scala)
java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.base/java.lang.reflect.Method.invoke(Method.java:568)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:282)
py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
py4j.commands.CallCommand.execute(CallCommand.java:79)
py4j.GatewayConnection.run(GatewayConnection.java:238)
java.base/java.lang.Thread.run(Thread.java:833)
2023-05-25 20:38:22.264 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.266 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.268 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.270 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.309 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.312 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.314 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.317 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.319 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.321 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.324 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.326 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.328 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.330 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.333 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.335 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.338 ERROR SparkContext:94 - Error initializing SparkContext.
java.net.BindException: Cannot assign requested address: Service &#x27;sparkDriver&#x27; failed after 16 retries (on a random free port)! Consider explicitly setting the appropriate binding address for the service &#x27;sparkDriver&#x27; (for example spark.driver.bindAddress for SparkDriver) to the correct binding address.
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:555)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.netBind(ServerSocketChannelImpl.java:337)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:294)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:134)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:562)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1334)
	at io.netty.channel.AbstractChannelHandlerContext.invokeBind(AbstractChannelHandlerContext.java:506)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:491)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:973)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:260)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:356)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:833)
Initializing Hail with default parameters...
2023-05-25 20:38:22.356 WARN  SparkContext:69 - Another SparkContext is being constructed (or threw an exception in its constructor). This may indicate an error, since only one SparkContext should be running in this JVM (see SPARK-2243). The other SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:85)
is.hail.backend.spark.SparkBackend$.configureAndCreateSparkContext(SparkBackend.scala:148)
is.hail.backend.spark.SparkBackend$.apply(SparkBackend.scala:230)
is.hail.backend.spark.SparkBackend.apply(SparkBackend.scala)
java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.base/java.lang.reflect.Method.invoke(Method.java:568)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:282)
py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
py4j.commands.CallCommand.execute(CallCommand.java:79)
py4j.GatewayConnection.run(GatewayConnection.java:238)
java.base/java.lang.Thread.run(Thread.java:833)
2023-05-25 20:38:22.382 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.384 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.386 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.389 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.391 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.393 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.395 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.397 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.399 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.401 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.404 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.406 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.409 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.411 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.413 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.415 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.419 ERROR SparkContext:94 - Error initializing SparkContext.
java.net.BindException: Cannot assign requested address: Service &#x27;sparkDriver&#x27; failed after 16 retries (on a random free port)! Consider explicitly setting the appropriate binding address for the service &#x27;sparkDriver&#x27; (for example spark.driver.bindAddress for SparkDriver) to the correct binding address.
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:555)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.netBind(ServerSocketChannelImpl.java:337)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:294)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:134)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:562)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1334)
	at io.netty.channel.AbstractChannelHandlerContext.invokeBind(AbstractChannelHandlerContext.java:506)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:491)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:973)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:260)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:356)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:833)

Quitting from lines 69-79 [do17] (large_t2t.Rmd)
Error: processing vignette &#x27;large_t2t.Rmd&#x27; failed with diagnostics:
py4j.protocol.Py4JJavaError: An error occurred while calling z:is.hail.backend.spark.SparkBackend.apply.
&lt;... omitted ...&gt;a:491)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:973)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:260)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:356)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:833)

See `reticulate::py_last_error()` for details
--- failed re-building ‘large_t2t.Rmd’

--- re-building ‘ukbb.Rmd’ using rmarkdown
2023-05-25 20:38:22.518 WARN  SparkContext:69 - Another SparkContext is being constructed (or threw an exception in its constructor). This may indicate an error, since only one SparkContext should be running in this JVM (see SPARK-2243). The other SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:85)
is.hail.backend.spark.SparkBackend$.configureAndCreateSparkContext(SparkBackend.scala:148)
is.hail.backend.spark.SparkBackend$.apply(SparkBackend.scala:230)
is.hail.backend.spark.SparkBackend.apply(SparkBackend.scala)
java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.base/java.lang.reflect.Method.invoke(Method.java:568)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:282)
py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
py4j.commands.CallCommand.execute(CallCommand.java:79)
py4j.GatewayConnection.run(GatewayConnection.java:238)
java.base/java.lang.Thread.run(Thread.java:833)
2023-05-25 20:38:22.542 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.545 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.547 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.549 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.551 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.554 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.556 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.558 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.560 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.562 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.564 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.567 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.569 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.571 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.573 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.576 WARN  Utils:69 - Service &#x27;sparkDriver&#x27; could not bind on a random free port. You may check whether configuring an appropriate binding address.
2023-05-25 20:38:22.579 ERROR SparkContext:94 - Error initializing SparkContext.
java.net.BindException: Cannot assign requested address: Service &#x27;sparkDriver&#x27; failed after 16 retries (on a random free port)! Consider explicitly setting the appropriate binding address for the service &#x27;sparkDriver&#x27; (for example spark.driver.bindAddress for SparkDriver) to the correct binding address.
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:555)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.netBind(ServerSocketChannelImpl.java:337)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:294)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:134)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:562)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1334)
	at io.netty.channel.AbstractChannelHandlerContext.invokeBind(AbstractChannelHandlerContext.java:506)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:491)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:973)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:260)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:356)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:833)

Quitting from lines 41-45 [getukbb] (ukbb.Rmd)
Error: processing vignette &#x27;ukbb.Rmd&#x27; failed with diagnostics:
no ukbb_sumst in cache and cannot populate with download, try another method.
--- failed re-building ‘ukbb.Rmd’

SUMMARY: processing the following files failed:
  ‘gwas_tut.Rmd’ ‘large_t2t.Rmd’ ‘ukbb.Rmd’

Error: Vignette re-building failed.
Execution halted
</PRE>
</DIV></BODY>
</HTML>
